{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1d1995",
   "metadata": {},
   "source": [
    "# N-Tuple Learning with Monte Carlo methods\n",
    "\n",
    "Created 2025-07-17\n",
    "\n",
    "*Summary*: The original n-tuple network was not working well. The idea is to switch to MC and try some new ideas:\n",
    "- Instead of TD learning, use Monte Carlo methods and train the model _after_ the episode\n",
    "    - This should also increase the training speed\n",
    "- Predict the value function instead of the action value function\n",
    "- Update towards the final reward (and not the reward from step n to n+1).\n",
    "    - May fix the problem that the agent is prefering low merges due to immediate reward, while the optimal solution is mostly to wait for a higher merge\n",
    "    - Combined with the switch to a value function the score gets a meaning: The average score given the current board"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
