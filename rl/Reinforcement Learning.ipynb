{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6df0e2",
   "metadata": {},
   "source": [
    "# Reinforcement Learning on 2048\n",
    "Created 25.06.2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8523cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipyevents import Event\n",
    "import time\n",
    "import gymnasium as gym\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691bd384",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, str(Path(\"..\")))\n",
    "import andreas2048\n",
    "from andreas2048.game import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b90309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from andreas2048 import gym2048\n",
    "#env = gym.make(\"andreas_2048\")\n",
    "env = gym2048.Env2048()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511e2b88",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "STOP",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSTOP\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: STOP"
     ]
    }
   ],
   "source": [
    "raise RuntimeError(\"STOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd0508",
   "metadata": {},
   "source": [
    "### 1 Interactive game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bae914",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "game = andreas2048.Game(shape=(4,4))\n",
    "plot_arrows = False\n",
    "stdout = sys.stdout\n",
    "\n",
    "def on_press(e):\n",
    "    global plot_arrows, stdout\n",
    "    if not game.alive:\n",
    "        return\n",
    "    match e.key:\n",
    "        case \"left\":\n",
    "            r = game.try_move(Action.LEFT)\n",
    "        case \"right\":\n",
    "            r = game.try_move(Action.RIGHT)\n",
    "        case \"up\":\n",
    "            r = game.try_move(Action.UP)\n",
    "        case \"down\":\n",
    "            r = game.try_move(Action.DOWN)\n",
    "        case \"r\":\n",
    "            plot_arrows = not plot_arrows\n",
    "        case \"z\":\n",
    "            game.undo()\n",
    "        case _:\n",
    "            r = False\n",
    "    game.plot_on_axis(ax, plot_arrows=plot_arrows)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.canvas.mpl_connect('key_press_event', on_press)\n",
    "game.plot_on_axis(ax)\n",
    "plt.show()\n",
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f10c2e",
   "metadata": {},
   "source": [
    "### 2 Random game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "score = []\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "for i in range(n):\n",
    "    game = Game()\n",
    "    while game.alive:\n",
    "        game.try_move(np.random.choice(np.array(game.get_moves())))\n",
    "    score.append(game.score)\n",
    "t1 = time.perf_counter()\n",
    "print(f\"Played {n} games in {(t1-t0):1.3f} s\")\n",
    "\n",
    "plt.hist(score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game()\n",
    "\n",
    "while game.alive:\n",
    "    game.try_move(np.random.choice(np.array(game.get_moves())))\n",
    "\n",
    "print(game)\n",
    "ax = plt.subplot()\n",
    "game.plot_on_axis(ax)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(game.score_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4333fe0",
   "metadata": {},
   "source": [
    "### 3 Gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "try:\n",
    "    check_env(env)\n",
    "    print(\"Environment passes all checks!\")\n",
    "except Exception as e:\n",
    "    print(f\"Environment has issues: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec75d4",
   "metadata": {},
   "source": [
    "##### 3.1 Testing some dummy policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e2ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Policy:\n",
    "\n",
    "    def __init__(self, env: gym.Env) -> None:\n",
    "        self.env = env\n",
    "\n",
    "    def get_action(self, obs: np.ndarray) -> Action:\n",
    "        return np.random.choice([Action.UP, Action.DOWN, Action.LEFT, Action.RIGHT])\n",
    "    \n",
    "\n",
    "class RDPolicy():\n",
    "    def __init__(self, env: gym2048.Env2048) -> None:\n",
    "        self.env = env\n",
    "\n",
    "    def get_action(self, obs: np.ndarray) -> Action:\n",
    "        moves = self.env.game.get_moves()\n",
    "        for a in [Action.DOWN, Action.RIGHT, Action.LEFT, Action.UP]:\n",
    "            if a in moves:\n",
    "                return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Agent:\n",
    "\n",
    "    def __init__(self, env: gym.Env) -> None:\n",
    "        self.env = env\n",
    "\n",
    "    def get_action(self, obs: np.ndarray) -> Action:\n",
    "        pass\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model =  torch.nn.Sequential(\n",
    "            torch.nn.Linear(4*4*16, out_features=128), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=128, out_features=128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=128,out_features=4)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
    "\n",
    "\n",
    "agent = RDPolicy(env)\n",
    "scores = []\n",
    "highest_tiles = []\n",
    "move_counts = []\n",
    "\n",
    "for episode in range(100):\n",
    "    # Start a new hand\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "\n",
    "    # Play one complete hand\n",
    "    while not done:\n",
    "        # Agent chooses action (initially random, gradually more intelligent)\n",
    "        action = agent.get_action(obs)\n",
    "\n",
    "        # Take action and observe result\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # Learn from this experience\n",
    "        #agent.update(obs, action, reward, terminated, next_obs)\n",
    "\n",
    "        # Move to next state\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "    scores.append(env.game.score)\n",
    "    highest_tiles.append(env.game.highest_tile)\n",
    "    move_counts.append(env.game.move_count)\n",
    "\n",
    "ax1 = plt.subplot()\n",
    "ax2 = ax1.twinx()\n",
    "ax3 = ax1.twinx()\n",
    "ax3.spines.right.set_position((\"axes\", 1.2))\n",
    "ax1.plot(scores, label=\"Scores\")\n",
    "p2 = ax2.plot(np.log2(highest_tiles), label=\"Highest tile\", c=\"orange\")\n",
    "p3 = ax3.plot(move_counts, label=\"Move count\", c=\"green\")\n",
    "ax1.set_xlabel(\"Episode\")\n",
    "ax1.set_ylabel(\"Score\")\n",
    "ax2.set_ylabel(\"Highest Tile\")\n",
    "ax3.set_ylabel(\"Move count\")\n",
    "ax2.yaxis.label.set_color(p2[0].get_color())\n",
    "ax3.yaxis.label.set_color(p3[0].get_color())\n",
    "ax2.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: f\"{2**x:n}\"))\n",
    "ax2.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
